import numpy as np
import os

# =====================================================================
# íŒŒì¼ ê²½ë¡œ ì„¤ì •
# =====================================================================
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(SCRIPT_DIR, "../../data")
INPUT_DIR = os.path.join(DATA_DIR, "input")
OUTPUT_DIR = os.path.join(DATA_DIR, "output")

# ì…ë ¥ íŒŒì¼
ORIGINAL_FEATURE_PATH = os.path.join(INPUT_DIR, "03_re-ranking_features_pqD_residual.npz")
OOF_PRED_PATH = os.path.join(OUTPUT_DIR, "oof", "12_residual_mlp_quantization_int8_norm_scaled_oof.npz")

# ì¶œë ¥ íŒŒì¼
OUTPUT_FEATURE_PATH = os.path.join(INPUT_DIR, "22_re-ranking_pqD_pred_resD_int8_norm_scaled.npz")

print("="*70)
print("ğŸ“‚ OOF ì˜ˆì¸¡ ê¸°ë°˜ Re-ranking Feature ìƒì„±")
print("="*70)

# =====================================================================
# 1. ë°ì´í„° ë¡œë“œ
# =====================================================================
print("\n1ï¸âƒ£  ë°ì´í„° ë¡œë“œ")

# ì›ë³¸ feature ë¡œë“œ
with np.load(ORIGINAL_FEATURE_PATH) as f:
    original_data = f['data']

print(f"âœ“ Original Data Shape: {original_data.shape}")

# Featureì™€ Label ë¶„ë¦¬
X_original = original_data[:, :-1]
y_original = original_data[:, -1:]

print(f"âœ“ Original Features Shape: {X_original.shape}")
print(f"âœ“ Original Label Shape: {y_original.shape}")

# ì• 16ê°œ featureë§Œ ì¶”ì¶œ (PQ Distance)
pq_dist_features = X_original[:, :16]
print(f"âœ“ PQ Distance Features Shape: {pq_dist_features.shape}")

# ë’¤ 16ê°œ feature (Residual ê´€ë ¨ - ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
residual_features = X_original[:, 16:]
print(f"âœ“ Original Residual Features Shape: {residual_features.shape} (will be replaced)")

# OOF ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ
with np.load(OOF_PRED_PATH) as f:
    oof_preds = f['pred']

print(f"âœ“ OOF Predictions Shape: {oof_preds.shape}")

# =====================================================================
# 2. ë°ì´í„° ì¬êµ¬ì„±
# =====================================================================
print("\n2ï¸âƒ£  ë°ì´í„° í˜•íƒœ í™•ì¸ ë° ì¬êµ¬ì„±")

num_samples = original_data.shape[0]
print(f"âœ“ Number of samples in original data: {num_samples}")

# OOF ì˜ˆì¸¡ì„ (10000, 16) í˜•íƒœë¡œ reshape
oof_preds_reshaped = oof_preds.reshape(10000, 16)
print(f"âœ“ OOF Preds Reshaped: {oof_preds_reshaped.shape}")

# ì›ë³¸ ë°ì´í„° í˜•íƒœì— ë”°ë¼ ì²˜ë¦¬
if num_samples == 10000:
    print(f"âœ“ Original dataëŠ” ì´ë¯¸ (10000, 33) í˜•íƒœì…ë‹ˆë‹¤.")
    pq_dist_reshaped = pq_dist_features  # (10000, 16)
    final_labels = y_original  # (10000, 1)
    
elif num_samples == 160000:
    print(f"âœ“ Original dataëŠ” (160000, 33) = (10000 queries Ã— 16 candidates) í˜•íƒœì…ë‹ˆë‹¤.")
    # PQ Distance reshape
    pq_dist_reshaped = pq_dist_features.reshape(10000, 16)
    # Label reshape - ê° queryë‹¹ ì²« ë²ˆì§¸ labelë§Œ
    final_labels = y_original.reshape(10000, 16)[:, 0:1]
    
else:
    raise ValueError(f"Unexpected number of samples: {num_samples}")

print(f"âœ“ PQ Distance Reshaped: {pq_dist_reshaped.shape}")
print(f"âœ“ Final Labels Shape: {final_labels.shape}")

# =====================================================================
# 3. ìƒˆë¡œìš´ Feature ì„¤ì •
# =====================================================================
print("\n3ï¸âƒ£  ìƒˆë¡œìš´ Residual Feature ì„¤ì •")

# OOF ì˜ˆì¸¡ê°’ì„ ê·¸ëŒ€ë¡œ ìƒˆë¡œìš´ residual featureë¡œ ì‚¬ìš©
new_residual_features = oof_preds_reshaped  # (10000, 16)

print(f"âœ“ New Residual Features Shape: {new_residual_features.shape}")
print(f"âœ“ New Residual Features - Mean: {new_residual_features.mean():.4f}, Std: {new_residual_features.std():.4f}")
print(f"âœ“ New Residual Features - Min: {new_residual_features.min():.4f}, Max: {new_residual_features.max():.4f}")

# =====================================================================
# 4. Feature ë³‘í•©
# =====================================================================
print("\n4ï¸âƒ£  Feature ë³‘í•©")

# PQ Distance (16) + OOF Predicted Residual (16) = 32 features
final_features = np.hstack([pq_dist_reshaped, new_residual_features])  # (10000, 32)

print(f"âœ“ Final Features Shape: {final_features.shape}")
print(f"âœ“ Final Labels Shape: {final_labels.shape}")

# Label ë¶„í¬ í™•ì¸
print(f"âœ“ Label Distribution - 0: {np.sum(final_labels == 0)}, 1: {np.sum(final_labels == 1)}")

# =====================================================================
# 5. ìµœì¢… ë°ì´í„° ê²°í•© ë° ì €ì¥
# =====================================================================
print("\n5ï¸âƒ£  ìµœì¢… ë°ì´í„° ê²°í•© ë° ì €ì¥")

# Features + Label ê²°í•©
final_data = np.hstack([final_features, final_labels])  # (10000, 33)

print(f"âœ“ Final Data Shape: {final_data.shape}")

# ì €ì¥
os.makedirs(os.path.dirname(OUTPUT_FEATURE_PATH), exist_ok=True)
np.savez_compressed(OUTPUT_FEATURE_PATH, data=final_data)

print(f"\nâœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {OUTPUT_FEATURE_PATH}")

# =====================================================================
# 6. ê²€ì¦
# =====================================================================
print("\n" + "="*70)
print("6ï¸âƒ£  ì €ì¥ëœ íŒŒì¼ ê²€ì¦")
print("="*70)

with np.load(OUTPUT_FEATURE_PATH) as f:
    loaded_data = f['data']

print(f"\nâœ“ Loaded Data Shape: {loaded_data.shape}")
print(f"âœ“ Expected Shape: (10000, 33)")
print(f"âœ“ Match: {'âœ… OK' if loaded_data.shape == (10000, 33) else 'âŒ MISMATCH'}")

print(f"\nâœ“ Feature Statistics:")
print(f"   - Features Shape: {loaded_data[:, :-1].shape}")
print(f"   - Features Mean: {loaded_data[:, :-1].mean():.4f}")
print(f"   - Features Std: {loaded_data[:, :-1].std():.4f}")

print(f"\nâœ“ Label Statistics:")
print(f"   - Label Shape: {loaded_data[:, -1:].shape}")
print(f"   - Label 0: {np.sum(loaded_data[:, -1] == 0)}")
print(f"   - Label 1: {np.sum(loaded_data[:, -1] == 1)}")

print("\n" + "="*70)
print("[Feature êµ¬ì„± (33 dims)]")
print("  - PQ Distance Features:         16 dims (ì• 16ê°œ)")
print("  - OOF Predicted Residual Dist:  16 dims (MLP ì˜ˆì¸¡ê°’)")
print("  - Label:                         1 dim")
print("="*70)

print("\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")